{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import KFold\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'simulated.sin'\n",
    "test_fold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features, target, and fold\n",
    "folds_df = pd.read_csv(f'../../data/{dataset}/folds.csv')\n",
    "target_df = pd.read_csv(f'../../data/{dataset}/targets.csv')\n",
    "features_df = pd.read_csv(f'../../data/{dataset}/features.csv')\n",
    "\n",
    "# Split data into training and test sets based on the fold\n",
    "train_ids = folds_df[folds_df['fold'] != test_fold].index\n",
    "test_ids = folds_df[folds_df['fold'] == test_fold].index\n",
    "\n",
    "# Prepare train and test sequences as arrays\n",
    "X_train = features_df.loc[train_ids].values\n",
    "y_train = target_df.loc[train_ids].values\n",
    "X_test = features_df.loc[test_ids].values\n",
    "y_test = target_df.loc[test_ids].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = copy.deepcopy(np.exp(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'objective': ['survival:aft'],\n",
    "    'eval_metric': ['aft-nloglik'],\n",
    "    'aft_loss_distribution': ['normal'],\n",
    "    'learning_rate': [0.001],\n",
    "    'max_depth': [10],\n",
    "    'min_child_weight': [0.001],\n",
    "    'reg_alpha': [0.001],\n",
    "    'reg_lambda': [0.001, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599\n",
      "1862\n",
      "1350\n",
      "2514\n",
      "1292\n",
      "1852\n",
      "1328\n",
      "2155\n",
      "1382\n",
      "2565\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_models = []\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train[train_idx])\n",
    "    dtrain.set_float_info('label_lower_bound', y_train[train_idx][:, 0])\n",
    "    dtrain.set_float_info('label_upper_bound', y_train[train_idx][:, 1])\n",
    "\n",
    "    dval = xgb.DMatrix(X_train[val_idx])\n",
    "    dval.set_float_info('label_lower_bound', y_train[val_idx][:, 0])\n",
    "    dval.set_float_info('label_upper_bound', y_train[val_idx][:, 1])\n",
    "\n",
    "    best_model = None\n",
    "    best_val_loss = float('inf')\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        model = xgb.train(params, dtrain, num_boost_round=5000, evals=[(dval, 'val')], early_stopping_rounds=20, verbose_eval=False)\n",
    "        print(model.best_iteration)\n",
    "        val_loss = model.best_score\n",
    "        if val_loss < best_val_loss:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_val_loss = val_loss\n",
    "    best_models.append(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction on the train set\n",
    "train_preds = np.zeros(X_train.shape[0])\n",
    "for model in best_models:\n",
    "    train_preds += model.predict(xgb.DMatrix(X_train))\n",
    "train_preds /= len(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86157687 2.13589764] \t 1.0809584379196167\n",
      "[0.84992599 2.08242692] \t 1.266771960258484\n",
      "[1.11573681        inf] \t 2.173110842704773\n",
      "[0.77855239        inf] \t 1.7251196503639221\n",
      "[1.60731486 2.8917215 ] \t 1.8122792720794678\n",
      "[1.32955859 2.39723742] \t 1.6269896268844604\n",
      "[1.13606325 2.66523171] \t 1.2981778383255005\n",
      "[0.21433351 0.5990645 ] \t 0.3945064961910248\n",
      "[2.83874485 6.58353609] \t 2.5536781787872314\n",
      "[1.21241229 3.68826811] \t 1.7227067708969117\n",
      "[1.08803466 2.15886366] \t 1.3804918766021728\n",
      "[0.30757787 0.76840296] \t 0.563711267709732\n",
      "[0.47781866 1.27125805] \t 0.7218468427658081\n",
      "[0.25102167 0.87039426] \t 0.6300823152065277\n",
      "[0.24069637 0.55527211] \t 0.38476194739341735\n",
      "[2.97607703 4.9217443 ] \t 2.5051972389221193\n",
      "[0.22948078        inf] \t 0.8790407180786133\n",
      "[0.         1.48966312] \t 0.33654133677482606\n",
      "[0.45168872 1.28867557] \t 0.6594567239284516\n",
      "[0.         1.02942871] \t 0.2930677503347397\n",
      "[1.51403913 2.72624717] \t 1.8429232358932495\n",
      "[1.03505234 3.67759866] \t 1.629229736328125\n",
      "[0.86667    2.37063535] \t 1.1722895145416259\n",
      "[0.21013061 0.62373979] \t 0.41719497442245485\n",
      "[0.56691834        inf] \t 1.2984908759593963\n",
      "[0.99533591 2.10164632] \t 1.3621867895126343\n",
      "[1.95333076 4.22693862] \t 2.1796427249908445\n",
      "[0.85313882 1.74910635] \t 1.0931275844573975\n",
      "[0.51446436        inf] \t 1.0632981300354003\n",
      "[2.30656407 4.841105  ] \t 2.2333531379699707\n",
      "[1.03888705 2.75821298] \t 1.414352536201477\n",
      "[1.79166257 4.28296274] \t 2.074039101600647\n",
      "[1.09546398 3.25676379] \t 1.711901807785034\n",
      "[1.37125997 3.85674283] \t 1.945379114151001\n",
      "[1.67696062 3.35992617] \t 1.8187493085861206\n",
      "[0.18054612 0.50500346] \t 0.36175803542137147\n",
      "[1.35078378 3.66356237] \t 1.7669607162475587\n",
      "[1.02954504 3.11797265] \t 1.804160714149475\n",
      "[1.84502901 3.86175985] \t 2.025224733352661\n",
      "[0.         2.71501099] \t 0.9636055827140808\n",
      "[0.        6.1011117] \t 0.5428062736988067\n",
      "[1.29653977 2.66757281] \t 1.8728981256484984\n",
      "[0.42410721 0.94694146] \t 0.6959247827529907\n",
      "[0.56283431 0.85145979] \t 0.5888663768768311\n",
      "[0.         3.49941216] \t 0.5051844477653503\n",
      "[0.         1.05593433] \t 0.3780043423175812\n",
      "[0.8700888  2.90124513] \t 1.380025863647461\n",
      "[0.6403829  1.46867554] \t 0.8375684976577759\n",
      "[1.69425311 3.96821749] \t 1.9754722118377686\n",
      "[1.33229497 4.72901058] \t 1.856439208984375\n",
      "[0.87529877 2.18128249] \t 1.352996563911438\n",
      "[0.32028278 0.79051709] \t 0.4988674521446228\n",
      "[1.33407878        inf] \t 2.4623991012573243\n",
      "[0.58008537        inf] \t 1.451790201663971\n",
      "[1.21182077 3.06527718] \t 1.5670936584472657\n",
      "[0.44159681 0.91041476] \t 0.5986308813095093\n",
      "[0.27017348 0.72644827] \t 0.514940059185028\n",
      "[0.79586715 3.24171983] \t 1.0872401773929596\n",
      "[0.62714532 1.5130296 ] \t 1.000078523159027\n",
      "[0.75261084 2.38713285] \t 1.3324928283691406\n",
      "[0.529971   0.97314518] \t 0.6913677453994751\n",
      "[0.32538408 0.7301524 ] \t 0.5033280849456787\n",
      "[0.74285456 1.49555593] \t 0.9865052819252014\n",
      "[1.50025786 3.51174477] \t 1.756752038002014\n",
      "[0.81828548        inf] \t 2.259755492210388\n",
      "[0.6957694  1.86891865] \t 1.0058313727378845\n",
      "[1.44689662 3.2285367 ] \t 1.7713002920150758\n",
      "[0.44830028 1.4190491 ] \t 0.7989397883415222\n",
      "[1.82153946 5.09953827] \t 2.201945996284485\n",
      "[0.         4.29757109] \t 0.45938617587089536\n",
      "[1.10596803 3.29231841] \t 1.6089523315429688\n",
      "[0.74184496 1.32316818] \t 0.991202437877655\n",
      "[0.33189056 0.74139925] \t 0.4775678992271423\n",
      "[0.         1.52940076] \t 0.27013644576072693\n",
      "[0.62646962 1.53572564] \t 0.8266858696937561\n",
      "[1.3135324  2.83336202] \t 1.46336590051651\n",
      "[0.4782771  0.87737657] \t 0.6514404296875\n",
      "[0.         3.09391104] \t 0.46907057762146\n",
      "[0.89020723 2.75732774] \t 1.2863457918167114\n",
      "[0.67751472 1.1601566 ] \t 0.8615143060684204\n",
      "[1.55241068 3.21931306] \t 1.6755343914031982\n",
      "[1.60421092 4.60330719] \t 2.0934095859527586\n",
      "[0.34042345 0.91679444] \t 0.6006823420524597\n",
      "[0.5514473  1.08635603] \t 0.7889879584312439\n",
      "[0.52792028 1.52991779] \t 0.7255543768405914\n",
      "[1.2356041 4.2199657] \t 1.8475161075592041\n",
      "[0.26306661 0.69445633] \t 0.4740013241767883\n",
      "[1.3332799  3.23175715] \t 1.5723416447639464\n",
      "[0.34050754 0.9476889 ] \t 0.6195759057998658\n",
      "[0.52048563 1.24602315] \t 0.7855022549629211\n",
      "[0.33175949 0.668272  ] \t 0.47953909635543823\n",
      "[0.         6.25763301] \t 0.6350501954555512\n",
      "[1.80529859 2.79176217] \t 2.020573449134827\n",
      "[1.38075024        inf] \t 2.6771761417388915\n",
      "[0.16157514 0.57432893] \t 0.4504411995410919\n",
      "[0.88954961        inf] \t 2.1711488485336305\n",
      "[1.89192532        inf] \t 2.6125104069709777\n",
      "[0.23079579 0.69470777] \t 0.4449059069156647\n",
      "[0.15152328 0.41510698] \t 0.3147381663322449\n",
      "[1.6951852 3.4145783] \t 1.7886898994445801\n",
      "[0.         2.76518904] \t 0.39456596970558167\n",
      "[1.26638198 2.45197053] \t 1.6496061325073241\n",
      "[1.09447632 2.56787575] \t 1.4926417112350463\n",
      "[0.7111414  2.72157838] \t 1.2564467668533326\n",
      "[0.24060974 0.71366401] \t 0.44479262828826904\n",
      "[0.2514616  0.59434697] \t 0.39480748772621155\n",
      "[0.         2.95557436] \t 0.8526043236255646\n",
      "[2.26019027        inf] \t 2.71340012550354\n",
      "[1.42231809 3.98838346] \t 1.9005988597869874\n",
      "[1.2905184 2.3941398] \t 1.506956195831299\n",
      "[0.15846207 0.46377582] \t 0.3634640574455261\n",
      "[2.58688642 5.52325853] \t 2.1662267565727236\n",
      "[0.75675403 1.69720368] \t 0.9516301631927491\n",
      "[1.3540282  3.60691559] \t 1.590714406967163\n",
      "[1.09215849 2.88242513] \t 1.6216979026794434\n",
      "[0.23783336 0.75207291] \t 0.49138654470443727\n",
      "[0.62462613 1.50538247] \t 0.7242696523666382\n",
      "[0.21430051 0.76768714] \t 0.4565310120582581\n",
      "[1.63063906 3.83013864] \t 1.7623982906341553\n",
      "[0.26786799 0.70251958] \t 0.44070815443992617\n",
      "[0.71216262 1.76029956] \t 0.908436405658722\n",
      "[0.75033088 2.1511509 ] \t 0.9646928191184998\n",
      "[0.31944505 0.93994398] \t 0.6258873105049133\n",
      "[1.23500868        inf] \t 2.2966562509536743\n",
      "[0.21064817 0.55961737] \t 0.3660604655742645\n",
      "[1.00967551 2.99660206] \t 1.3637359142303467\n",
      "[1.62741522 2.8006177 ] \t 1.8512010097503662\n",
      "[0.94282084 1.98500216] \t 1.3576530933380127\n",
      "[2.43670569        inf] \t 2.9336623430252073\n",
      "[0.95286504 2.59827302] \t 1.1825955271720887\n",
      "[0.18825798 0.45900095] \t 0.32419076561927795\n",
      "[0.33428445 0.98302768] \t 0.604613983631134\n",
      "[0.         1.92289526] \t 0.5611617088317871\n",
      "[0.20494779 0.43564308] \t 0.3249874830245972\n",
      "[0.55035321 1.35719626] \t 0.6966566681861878\n",
      "[0.94812209 1.71644107] \t 1.3374496698379517\n",
      "[1.4330915  3.85031514] \t 1.8934675216674806\n",
      "[0.8524617  2.05584509] \t 1.0141103088855743\n",
      "[0.17407292 0.64309296] \t 0.3638171315193176\n",
      "[1.66333895 5.23685957] \t 2.2188833475112917\n",
      "[0.23056972 0.86224226] \t 0.45097053050994873\n",
      "[1.31508723 2.31843178] \t 1.495583462715149\n",
      "[0.         0.56848691] \t 0.25130065679550173\n",
      "[0.4215567  0.98619912] \t 0.6237314105033874\n",
      "[0.64307688 2.00759402] \t 1.0834502696990966\n",
      "[1.39475671 2.93375156] \t 1.845748233795166\n",
      "[0.         3.80297251] \t 0.6603183031082154\n",
      "[0.52667796 2.36503069] \t 1.046721911430359\n",
      "[1.32140293 3.52573526] \t 1.6395384073257446\n",
      "[0.         2.08809256] \t 0.6821374237537384\n",
      "[0.53749168 1.19482293] \t 0.7255459070205689\n",
      "[0.42193289 0.96213741] \t 0.5909859538078308\n",
      "[1.01337972        inf] \t 2.7129114866256714\n",
      "[1.23311686 2.90757674] \t 1.7759137868881225\n",
      "[1.46004608 4.27113244] \t 1.7974721908569335\n",
      "[0.96224229 2.57045262] \t 1.399311399459839\n",
      "[0.62459303 2.06605502] \t 1.137691605091095\n",
      "[1.61213599 4.34399313] \t 1.7397398471832275\n",
      "[1.56280456 3.56443302] \t 1.6328320741653441\n",
      "[0.2918355  0.49760236] \t 0.48245181441307067\n"
     ]
    }
   ],
   "source": [
    "# print y_test along with its prediction\n",
    "for i in range(len(y_train)):\n",
    "    print(f'{y_train[i]} \\t {train_preds[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 156\n",
      "Incorrect: 4\n"
     ]
    }
   ],
   "source": [
    "# count the number of correct predictions from the test set\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i, 0] < train_preds[i] and y_train[i, 1] > train_preds[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "# print the number of correct and incorrect predictions\n",
    "print(f'Correct: {correct}')\n",
    "print(f'Incorrect: {incorrect}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "test_preds = np.zeros(X_test.shape[0])\n",
    "for model in best_models:\n",
    "    test_preds += model.predict(dtest)\n",
    "test_preds /= len(best_models)\n",
    "test_preds = np.log(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.228758  0.583414] \t 0.3615355853369168\n",
      "[0.157429 0.960006] \t 0.5507345153774135\n",
      "[    -inf 0.582814] \t 0.46914526699786296\n",
      "[0.470278 1.156113] \t 0.3801672374240819\n",
      "[0.183034 1.112268] \t -0.4035246494965674\n",
      "[0.49832 1.41573] \t -0.31795834850781735\n",
      "[-0.432071  0.384011] \t -0.30219474687009773\n",
      "[    -inf 0.637887] \t 0.4850622185650307\n",
      "[-1.529285 -0.523827] \t -0.4725259669836724\n",
      "[-0.807926 -0.330616] \t -0.5786799562474638\n",
      "[0.592316 1.380831] \t 0.7646765894070523\n",
      "[0.234569 1.113224] \t 0.23060074267848285\n",
      "[-1.705988 -0.6865  ] \t -0.9661809264094748\n",
      "[0.494488 1.229534] \t 0.45903055576266744\n",
      "[0.184802 1.159551] \t 0.30190315795794653\n",
      "[-0.649578  0.167296] \t -0.555204481225148\n",
      "[0.266344      inf] \t 0.7925693311942511\n",
      "[-0.700897  0.807319] \t -0.4984561773477483\n",
      "[0.062691 0.747556] \t -0.4356985605264991\n",
      "[0.63216  1.592851] \t 0.4380651932705141\n",
      "[-1.452828 -0.643022] \t -0.9669616463285174\n",
      "[0.73509  1.644592] \t 0.21614401395177318\n",
      "[0.621593      inf] \t 0.45263883583573333\n",
      "[0.558498      inf] \t 0.6189846824246577\n",
      "[0.115978 1.246106] \t 0.25532901425816046\n",
      "[0.669298 2.212648] \t 0.3746502709045559\n",
      "[-0.29396   0.325471] \t -0.14072878091077873\n",
      "[-0.110292  1.045349] \t 0.057799779272047595\n",
      "[-1.644409 -0.395689] \t -0.5819894863866037\n",
      "[0.055888 0.673859] \t 0.3940171866101387\n",
      "[-0.066819       inf] \t 0.541612319162732\n",
      "[-1.445161 -0.342919] \t -0.8401102244905259\n",
      "[0.083207      inf] \t 0.6406435561799094\n",
      "[-0.675999  0.376284] \t -0.3430776509515195\n",
      "[-0.251211  0.631441] \t -0.32770647100215333\n",
      "[     -inf -0.960937] \t -0.770326190548435\n",
      "[0.079224      inf] \t 0.14430324340196768\n",
      "[-0.036498  1.215397] \t 0.4180057982478765\n",
      "[0.66221  1.920584] \t 0.5406806554050755\n",
      "[0.336633 1.588906] \t 0.3798044484221045\n"
     ]
    }
   ],
   "source": [
    "# print y_test along with its prediction\n",
    "for i in range(len(y_test)):\n",
    "    print(f'{y_test[i]} \\t {test_preds[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 26\n",
      "Incorrect: 14\n"
     ]
    }
   ],
   "source": [
    "# count the number of correct predictions from the test set\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i, 0] < test_preds[i] and y_test[i, 1] > test_preds[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "# print the number of correct and incorrect predictions\n",
    "print(f'Correct: {correct}')\n",
    "print(f'Incorrect: {incorrect}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
