{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmit_functions import mmit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../../data'\n",
    "datasets = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set and test set\n",
    "for dataset in datasets:\n",
    "    folds_df    = pd.read_csv(f'../../data/{dataset}/folds.csv')\n",
    "    features_df = pd.read_csv(f'../../data/{dataset}/features.csv').astype(np.float32)\n",
    "    target_df   = pd.read_csv(f'../../data/{dataset}/targets.csv').astype(np.float32)\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for test_fold in sorted(np.unique(folds_df['fold'])):\n",
    "        train_indices = folds_df[folds_df['fold'] != test_fold].index\n",
    "        test_indices = folds_df[folds_df['fold'] == test_fold].index\n",
    "\n",
    "        # Filter the DataFrames by index\n",
    "        X_train = features_df.loc[train_indices].values  \n",
    "        X_test = features_df.loc[test_indices].values  \n",
    "        y_train = target_df.loc[train_indices].values  \n",
    "\n",
    "        # Perform 3-fold cross-validation on the training set\n",
    "        kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        max_depths = [5, 10, 15, 20, 25, 30]\n",
    "        best_models = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_subtrain, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_subtrain, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "            best_model = None\n",
    "            best_hinge_error = float('inf')\n",
    "\n",
    "            # Train models with different max_depth values\n",
    "            for max_depth in max_depths:\n",
    "                tree = mmit(max_depth=max_depth)\n",
    "                tree.fit(X_subtrain, y_subtrain)\n",
    "\n",
    "                # Predict on validation set\n",
    "                y_val_pred = tree.predict(X_val)\n",
    "\n",
    "                # Compute hinge error for validation set\n",
    "                y_val_low = y_val[:, 0] + tree.margin_length\n",
    "                y_val_up = y_val[:, 1] - tree.margin_length\n",
    "                hinge_error = np.sum(tree.hinge_error(y_val_pred, y_val_low, y_val_up))\n",
    "\n",
    "                # Track the best model based on hinge error\n",
    "                if hinge_error < best_hinge_error:\n",
    "                    best_hinge_error = hinge_error\n",
    "                    best_model = tree\n",
    "\n",
    "            # Store the best model for this subtrain/val pair\n",
    "            best_models.append(best_model)\n",
    "\n",
    "        # Predict on the test set using the average prediction from the 3 best models\n",
    "        target_mat_pred = np.mean([model.predict(X_test) for model in best_models], axis=0)\n",
    "        prediction = pd.DataFrame({'pred': target_mat_pred})\n",
    "        prediction.to_csv(f\"predictions/{dataset}.{test_fold}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmit_functions import mmit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "from joblib import Parallel, delayed  # For parallel processing\n",
    "\n",
    "folder_path = '../../data'\n",
    "datasets = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "\n",
    "def process_dataset(dataset):\n",
    "    # Load data\n",
    "    folds_df = pd.read_csv(f'../../data/{dataset}/folds.csv')\n",
    "    features_df = pd.read_csv(f'../../data/{dataset}/features.csv').astype(np.float32)\n",
    "    target_df = pd.read_csv(f'../../data/{dataset}/targets.csv').astype(np.float32)\n",
    "\n",
    "    max_depths = [5, 10, 15, 20, 25, 30]\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    # Iterate over test folds\n",
    "    for test_fold in sorted(np.unique(folds_df['fold'])):\n",
    "        train_indices = folds_df[folds_df['fold'] != test_fold].index\n",
    "        test_indices = folds_df[folds_df['fold'] == test_fold].index\n",
    "\n",
    "        X_train = features_df.loc[train_indices].values\n",
    "        X_test = features_df.loc[test_indices].values\n",
    "        y_train = target_df.loc[train_indices].values\n",
    "\n",
    "        def train_and_evaluate(train_idx, val_idx):\n",
    "            X_subtrain, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_subtrain, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "            best_model = None\n",
    "            best_hinge_error = float('inf')\n",
    "\n",
    "            for max_depth in max_depths:\n",
    "                tree = mmit(max_depth=max_depth)\n",
    "                tree.fit(X_subtrain, y_subtrain)\n",
    "\n",
    "                # Predict on validation set\n",
    "                y_val_pred = tree.predict(X_val)\n",
    "\n",
    "                # Compute hinge error\n",
    "                y_val_low = y_val[:, 0] + tree.margin_length\n",
    "                y_val_up = y_val[:, 1] - tree.margin_length\n",
    "                hinge_error = np.sum(tree.hinge_error(y_val_pred, y_val_low, y_val_up))\n",
    "\n",
    "                if hinge_error < best_hinge_error:\n",
    "                    best_hinge_error = hinge_error\n",
    "                    best_model = tree\n",
    "\n",
    "            return best_model\n",
    "\n",
    "        # Train models in parallel\n",
    "        best_models = Parallel(n_jobs=-1)(\n",
    "            delayed(train_and_evaluate)(train_idx, val_idx) for train_idx, val_idx in kf.split(X_train)\n",
    "        )\n",
    "\n",
    "        # Predict on the test set using the average prediction\n",
    "        target_mat_pred = np.mean([model.predict(X_test) for model in best_models], axis=0)\n",
    "        prediction = pd.DataFrame({'pred': target_mat_pred})\n",
    "        prediction.to_csv(f\"predictions/{dataset}.{test_fold}.csv\", index=False)\n",
    "\n",
    "# Process all datasets\n",
    "Parallel(n_jobs=-1)(delayed(process_dataset)(dataset) for dataset in datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
