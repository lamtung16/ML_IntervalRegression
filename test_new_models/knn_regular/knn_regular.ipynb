{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKNNRegressor:\n",
    "    def __init__(self, margin=0, n_neighbors=5, custom_func=None):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.custom_func = custom_func if custom_func is not None else self.getting_best_mu\n",
    "        self.margin = margin\n",
    "        self.knn = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.scaler = StandardScaler()  # Normalize features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.X = X_scaled\n",
    "        self.y = y\n",
    "        self.knn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.knn.fit(X_scaled)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_scaled = self.scaler.transform(X_test)  # Normalize test data\n",
    "        distances, indices = self.knn.kneighbors(X_test_scaled)\n",
    "        predictions = []\n",
    "        for neighbors in indices:\n",
    "            neighbor_intervals = self.y[neighbors]\n",
    "            predictions.append(self.custom_func(neighbor_intervals))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def getting_best_mu(self, intervals):\n",
    "        # Adjust intervals with the margin\n",
    "        intervals = intervals + np.array([self.margin, -self.margin])\n",
    "        \n",
    "        # Ensure intervals are valid\n",
    "        mask = intervals[:, 1] < intervals[:, 0]\n",
    "        intervals[mask] = intervals[mask][:, ::-1]\n",
    "\n",
    "        # Extract unique endpoints from the intervals\n",
    "        endpoints = np.unique(intervals[np.isfinite(intervals)])\n",
    "        y_min, y_max = intervals[:, 0], intervals[:, 1]\n",
    "\n",
    "        # Calculate the loss when mu is below or above the interval\n",
    "        lower_loss = np.maximum(0, y_min[:, None] - endpoints)**2  # Loss when mu is below y_min\n",
    "        upper_loss = np.maximum(0, endpoints - y_max[:, None])**2  # Loss when mu is above y_max\n",
    "        losses = np.sum(lower_loss + upper_loss, axis=0)\n",
    "\n",
    "        # Find the mu that minimizes the loss\n",
    "        min_loss_idx = np.argmin(losses)\n",
    "        mu = endpoints[min_loss_idx]\n",
    "        return mu\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def hinge_error(self, y_pred, y_low, y_up):\n",
    "        y_pred, y_low, y_up = np.array(y_pred), np.array(y_low), np.array(y_up)\n",
    "        return (\n",
    "            self.relu(y_low - y_pred + self.margin) ** 2 +\n",
    "            self.relu(y_pred - y_up + self.margin) ** 2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../../data'\n",
    "datasets = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    folds_df = pd.read_csv(f'../../data/{dataset}/folds.csv')\n",
    "    features_df = pd.read_csv(f'../../data/{dataset}/features.csv').astype(np.float32)\n",
    "    target_df = pd.read_csv(f'../../data/{dataset}/targets.csv').astype(np.float32)\n",
    "\n",
    "    # Process folds sequentially\n",
    "    predictions = []\n",
    "    for test_fold in sorted(np.unique(folds_df['fold'])):\n",
    "        # Split data into training and test sets\n",
    "        train_indices = folds_df[folds_df['fold'] != test_fold].index\n",
    "        test_indices = folds_df[folds_df['fold'] == test_fold].index\n",
    "\n",
    "        # Filter the DataFrames by index\n",
    "        X_train = features_df.loc[train_indices].values\n",
    "        X_test = features_df.loc[test_indices].values\n",
    "        y_train = target_df.loc[train_indices].values\n",
    "\n",
    "        # Perform 5-fold cross-validation on the training set\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_errors = {K: [] for K in np.arange(1, int(np.sqrt(X_train.shape[0])))}  # Initialize fold_errors dictionary\n",
    "\n",
    "        # Loop over all possible values of k (number of neighbors)\n",
    "        for K in np.arange(1, int(np.sqrt(X_train.shape[0]))):\n",
    "            # Initialize error accumulation for this value of K\n",
    "            total_fold_error = 0\n",
    "\n",
    "            # Train and evaluate within the cross-validation loop\n",
    "            for train_idx, val_idx in kf.split(X_train):\n",
    "                X_subtrain, X_val = X_train[train_idx], X_train[val_idx]\n",
    "                y_subtrain, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "                # Train KNN model with the current value of K\n",
    "                knn = CustomKNNRegressor(n_neighbors=K)\n",
    "                knn.fit(X_subtrain, y_subtrain)\n",
    "\n",
    "                # Predict on validation set\n",
    "                y_val_pred = knn.predict(X_val)\n",
    "\n",
    "                # Compute hinge error for validation set\n",
    "                y_val_low = y_val[:, 0] + knn.margin\n",
    "                y_val_up = y_val[:, 1] - knn.margin\n",
    "                hinge_error = np.sum(knn.hinge_error(y_val_pred, y_val_low, y_val_up))\n",
    "\n",
    "                # Accumulate the fold error for this value of K\n",
    "                total_fold_error += hinge_error\n",
    "\n",
    "            # Store the average error for this value of K\n",
    "            fold_errors[K] = total_fold_error / 5  # Average over 5 folds\n",
    "\n",
    "        # Select the best K with the smallest average error\n",
    "        best_K = min(fold_errors, key=fold_errors.get)\n",
    "\n",
    "        # Train the final model on the entire training set using the best K\n",
    "        final_knn = CustomKNNRegressor(n_neighbors=best_K)\n",
    "        final_knn.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        target_mat_pred = final_knn.predict(X_test)\n",
    "        prediction = pd.DataFrame({'pred': target_mat_pred})\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # Save predictions for each fold\n",
    "    for test_fold, prediction in zip(sorted(np.unique(folds_df['fold'])), predictions):\n",
    "        prediction.to_csv(f\"predictions/{dataset}.{test_fold}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
